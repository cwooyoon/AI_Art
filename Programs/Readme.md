# AI Art Program...

## Deep Dream
* Everywhere you look nowadays you find AI. From filters on snap chat, tools in photoshop, the ads next to videos and even the video suggestions next to this video. Two such AI programs allow you to make amazing AI art and bend reality in weird ways.

* Style transfer allows you to take the style from one image, like Van Gogh's Starry Night, and transfer it to a different image. This allows you to quickly generate new master pieces by your favorite artists, or give something a fresh look. There is a version of this program that works on videos too which we'll explore in the future.

* Deep dream on the other hand is ai turned on it's head. Instead of using the AI to classify things, we allow it to manipulate an image to fit some of the data its already learned. This produces sureal images where animals and structure get generated out of noise.

* All of this is done in an online tool called Deep Dream Generator: https://deepdreamgenerator.com


* Some further reading and references:

* Original Paper Style Transfer - https://arxiv.org/pdf/1508.06576.pdf
* Deep Dream Article - https://research.googleblog.com/2015/...
* Deep Dream Video by computerphile - https://www.youtube.com/watch?v=BsSmB...


## DALL.E
* https://www.youtube.com/watch?v=y_TKakn3OPA
* https://openai.com/blog/dall-e/
* https://arxiv.org/abs/2102.12092
* https://arxiv.org/pdf/2102.12092.pdf
  - Zero-Shot Text-to-Image Generation
    - Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever
    - Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.

## AICAN
* https://aican.io/

## CLIP
* https://openai.com/blog/clip/
* https://blog.roboflow.com/how-to-use-openai-clip/
* https://blog.roboflow.com/how-we-built-paint-wtf-an-ai-that-judges-your-art-100-000-submissions/
* https://blog.roboflow.com/zero-shot-content-moderation-openai-new-clip-model/
* https://blog.roboflow.com/clip-model-eli5-beginner-guide/
* https://blog.roboflow.com/openai-clip-prompt-engineering/
* https://compvis.github.io/taming-transformers/
* CLIP+VQGAN Google Colab Notebook: https://bit.ly/clip-vqgan
* 
