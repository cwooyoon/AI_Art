# AI Art Program...

## DALL.E
* https://www.youtube.com/watch?v=y_TKakn3OPA
* https://openai.com/blog/dall-e/
* https://arxiv.org/abs/2102.12092
* https://arxiv.org/pdf/2102.12092.pdf
  - Zero-Shot Text-to-Image Generation
    - Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever
    - Text-to-image generation has traditionally focused on finding better modeling assumptions for training on a fixed dataset. These assumptions might involve complex architectures, auxiliary losses, or side information such as object part labels or segmentation masks supplied during training. We describe a simple approach for this task based on a transformer that autoregressively models the text and image tokens as a single stream of data. With sufficient data and scale, our approach is competitive with previous domain-specific models when evaluated in a zero-shot fashion.

## AICAN
* https://aican.io/

## CLIP
* https://openai.com/blog/clip/
* https://blog.roboflow.com/how-to-use-openai-clip/
* https://blog.roboflow.com/how-we-built-paint-wtf-an-ai-that-judges-your-art-100-000-submissions/
* https://blog.roboflow.com/zero-shot-content-moderation-openai-new-clip-model/
* https://blog.roboflow.com/clip-model-eli5-beginner-guide/
* https://blog.roboflow.com/openai-clip-prompt-engineering/
* https://compvis.github.io/taming-transformers/
* CLIP+VQGAN Google Colab Notebook: https://bit.ly/clip-vqgan
* 
